import cvxpy as cvx
import numpy as np
from scipy.optimize import root, minimize
from numpy.linalg import norm, inv, slogdet
import scipy.linalg as sla
from numpy import exp
import scipy.linalg as sla
import numpy.random as ra
import numpy.linalg as la
import scipy.stats
import ipdb
from Functions.objective_functions import LinearModel
from scipy.special import logsumexp
from myutils3_v2 import *
import calcsubset
     
'''Place holder class that all GLM bandit algorithms must inherit from GLM '''

def gloc_solve_by_cvx(d,S,theta_prime,At):
    th = cvx.Variable(d)
    obj = cvx.Minimize(cvx.quad_form(th - theta_prime, At))
    cons = [cvx.norm(th) <= S]

    prob = cvx.Problem(obj, cons)
    prob.solve()

    return np.array(th.value).flatten()

def calc_sqrt_beta_det2(d,t,R,ridge,delta,S,logdetV):
    return R * np.sqrt( logdetV - d*log(ridge) + log (1/(delta**2)) ) + sqrt(ridge) * S

def calc_sqrt_beta_det3(t,R,ridge,delta,S,logdetV,logdetV0):
    """ to allow diagonal regularization
    """
    return R * np.sqrt( logdetV - logdetV0 + log (1/(delta**2)) ) + sqrt(ridge) * S

def calc_sqrt_beta_det4(t,R,ridge,delta,Sp,logdetV,logdetV0):
    """ to allow diagonal regularization, actually I can have a better one.
    `Sp = sqrt(ridge) * S` in the previous versions.
    """
    return R * np.sqrt( logdetV - logdetV0 + log (1/(delta**2)) ) + Sp


def calc_sqrt_beta_thompson(d,t,R,delta):
   return R * np.sqrt(9 * d * np.log(t/delta))

def mu_logistic(z):
    return 1.0/(1.0+np.exp(-z))

def mu_probit(z):
    return scipy.stats.norm.cdf(z)

def logistic_loss_pm1(w, x, y):
    y = float(y)
    assert (y in [+1.0, -1.0])
    z = y *np.dot(x,w)
    return np.log(1 + np.exp(-z))

def logistic_loss_01(w, x, y):
    assert (y in [0.0, 1.0])
    yy = y * 2 - 1
    return logistic_loss_pm1(w,x,yy)

def logistic_loss_pm1_grad(w, x, y):
    y = float(y)
    assert (y in [+1.0, -1.0])
    z = y * np.dot(x,w)
    return - 1.0 / (1 + np.exp(z)) * (y*x)

def logistic_loss_01_grad(w, x, y):
    assert (y in [0.0, 1.0])
    yy = y * 2 - 1
    return logistic_loss_pm1_grad(w,x,yy)

def mfunc_logistic(z):
    return np.log(1.0 + np.exp(z))

def mfunc_logistic_der(z):
    return 1.0/(1.0 + np.exp(-z))

from sklearn import metrics
def evalAuc(banditObj, dataObj, nTry=1):
    """
        evaluates deployment performance by AUC. 
        repeats are important when the data is synthetic and generated by p(y|x)
    """
    aucList = []
    trainAucList = []
    testAucList = []
    N = dataObj.N
    for iTry in range(nTry):
        #- 1. generate the labels
        y = np.array([dataObj.get_reward(i) for i in range(dataObj.N)])
        #- 2. let the bandit compute the scores (0.0-1.0)
        pred = banditObj.predict(dataObj.X)
        #- 3. normalize the pred to be in (0.0-1.0)
        mini = pred.min()
        maxi = pred.max()
        yhat = (pred - mini) / (maxi - mini)
        #- 4. measure auc
        auc = metrics.roc_auc_score(y, yhat)

        assert(np.all(dataObj.X == banditObj.X))
        do_not_ask = banditObj.getDoNotAsk()
        trainAuc = metrics.roc_auc_score(y[do_not_ask], yhat[do_not_ask])

        testIdx = np.setdiff1d(np.arange(N), do_not_ask)
        testAuc = metrics.roc_auc_score(y[testIdx], yhat[testIdx])

        aucList.append(auc)
        trainAucList.append(trainAuc)
        testAucList.append(testAuc)

    return np.mean(aucList), np.mean(trainAucList), np.mean(testAucList)

################################################################################
# bandit classes
################################################################################
class Bandit(object):
    def __init__(self, X, theta):
        raise NotImplementedError()

    def next_arm(self):
        raise NotImplementedError()

    def update(self):
        raise NotImplementedError()

    def get_debug_dict(self):
        raise NotImplementedError()

class Glm(object):
    def __init__(self):
        raise NotImplementedError()


########################################
class BilinearOful(Bandit):
########################################
    """ this is now heavily modified for graph bandits.. for the original, please use the one in 'expr-nips17-post'
    Sp: 'S prime', for oful, should be \sqrt(lam) * (2-norm bound on theta) 
        For spectral bandit, should be a bound on ||\\theta||_{V_0}
    """
    def __init__(self, X, Z, lam, R, Sp, D=None, flags={}, subsample_func=None, subsample_rate=1.0, multiplier=1.0, binaryRewards=False, bArmRemoval=False):
        """
        D allows diagonal regularization.
        Warning: Sp must be set to `sqrt(lam) * S` for OFUL.
        """
        self.X = X
        self.Z = Z
        self.R = R
        self.lam = lam
        self.delta = .2
# 		self.S_frobnorm = S_frobnorm
# 		self.Sp = np.sqrt(self.lam) * self.S_frobnorm
        self.Sp = Sp
        self.flags = flags
        self.multiplier = float(multiplier)
        self.binaryRewards = binaryRewards
        self.bArmRemoval = bArmRemoval

        # more instance variables
        self.t = 1
        self.N1, self.d1 = self.X.shape
        self.N2, self.d2 = self.Z.shape

        # super arms
        self.N = self.N1 * self.N2
        self.d = self.d1 * self.d2
        self.W = np.zeros( (self.N, self.d) )
        for i in range(self.W.shape[0]):
            i1, i2 = np.unravel_index(i, (self.N1, self.N2))
            self.W[i,:] = np.outer(self.X[i1,:], self.Z[i2,:]).ravel()

        #- subsampling aspect (disabled for now)
        assert subsample_func == None
        self.subsample_func = None

        self.WTy = np.zeros(self.d)

        self.D = D
        if (self.D is None):
            self.Vt = self.lam * np.eye(self.d)
            self.invVt = np.eye(self.d) / self.lam
            self.W_invVt_norm_sq = np.sum(self.W * self.W, axis=1) / self.lam
            self.logdetV = self.d*log(self.lam)
        else:
            assert self.lam is None
            self.Vt = D
            self.invVt = np.diag(1/np.diag(self.Vt))
            self.W_invVt_norm_sq = np.sum((self.W*np.diag(self.invVt)) * self.W, axis=1)
            self.logdetV = np.sum(np.log(np.diag(self.Vt)))
        self.logdetV0 = self.logdetV

        self.sqrt_beta = calc_sqrt_beta_det4(self.t,self.R,self.lam,self.delta,self.Sp,self.logdetV, self.logdetV0)
        self.theta_hat = np.zeros(self.d)

        assert bArmRemoval == False # let's implement this later on.
        self.do_not_ask = []
        self.dbg_dict = {'multiplier':float(multiplier)}
        self.cache_valid_idx = np.arange(self.N)

    #@profile
    def next_arm(self):
        if (len(self.do_not_ask) == 0):
            valid_idx = self.cache_valid_idx
        else:
            valid_idx = setdiff1d(np.arange(self.N),self.do_not_ask)
        if (self.t == 1):
            return (ra.randint(self.N1), ra.randint(self.N2)), np.nan
        radius_sq = self.multiplier * (self.sqrt_beta)**2
        if (self.subsample_func == None):
#            obj_func = np.dot(self.W, self.theta_hat) + np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
#            A = np.dot(self.W, self.theta_hat)
            A = (self.X @ self.theta_hat.reshape(self.d1,self.d2) @ self.Z.T).ravel() 
            B = np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
            obj_func = A + B
            if (len(self.do_not_ask) == 0):
                chosen = np.argmax(obj_func)
            else:
                chosen_inner = np.argmax(obj_func[valid_idx])
                chosen = valid_idx[chosen_inner]
        else:
            raise NotImplementedError("use valid_idx")

        chosenPair = np.unravel_index(chosen, (self.N1,self.N2))
        return chosenPair, radius_sq

    def calc_index(self):
        """ newly written for `SpectralUCB`
        """
        radius_sq = self.multiplier * (self.sqrt_beta)**2
        obj_func = np.dot(self.W, self.theta_hat) + np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
        if (self.bArmRemoval):
            obj_func[self.do_not_ask] = -np.inf
        return obj_func

    def update(self, pulled_idx_pair, y_t):
        pulled_idx = np.ravel_multi_index(pulled_idx_pair, (self.N1,self.N2))
        wt = self.W[pulled_idx, :]

        if (self.binaryRewards):
            assert (y_t >= 0.0 and y_t <= 1.0)
            self.WTy += (2*y_t - 1) * wt
        else:
            self.WTy += y_t*wt
        self.Vt += np.outer(wt,wt)

        tempval1 = np.dot(self.invVt, wt)    # d by 1, O(d^2)
        tempval2 = np.dot(tempval1, wt)      # scalar, O(d)
        self.logdetV += log(1 + tempval2)

        if (self.t % 100 == 0):
            self.invVt = la.inv(self.Vt)
        else:
#            self.invVt -= np.outer(tempval1, tempval1) / (1 + tempval2)
            aVec = tempval1 / np.sqrt(1 + tempval2)
            self.invVt -= np.outer(aVec, aVec)

        if (self.subsample_func == None):
            # self.W_invVt_norm_sq = mahalanobis_norm_sq_batch(self.W, self.invVt)  # O(Nd^2) 
#            self.W_invVt_norm_sq -= (np.dot(self.W, tempval1) ** 2) / (1 + tempval2) # efficient update, O(Nd)
            v = (np.dot(self.X, tempval1.reshape(self.d1,self.d2)) @ self.Z.T).ravel()
            self.W_invVt_norm_sq -= (v ** 2) / (1 + tempval2) # efficient update, O(Nd)
            pass

        self.theta_hat = np.dot(self.invVt, self.WTy)
        if (self.bArmRemoval):
            self.do_not_ask.append( pulled_idx_pair )

        my_t = self.t + 1
        self.sqrt_beta = calc_sqrt_beta_det4(my_t,self.R,self.lam,self.delta,self.Sp,self.logdetV,self.logdetV0)

        self.t += 1

    def getDoNotAsk(self):
        return self.do_not_ask

    def predict(self, X=None):
        raise NotImplementedError()
        if X is None:
            X = self.X
        return X.dot(self.theta_hat)

    def get_debug_dict(self):
        return self.dbg_dict
########################################
class EFALB(Bandit):
########################################
    """ this is now heavily modified for graph bandits.. for the original, please use the one in 'expr-nips17-post'
    Sp: 'S prime', for oful, should be \sqrt(lam) * (2-norm bound on theta)
        For spectral bandit, should be a bound on ||\\theta||_{V_0}
    """
    def __init__(self, X, Z, lam, T, R, Sp, D=None, flags={}, subsample_func=None, subsample_rate=1.0, multiplier=1.0, binaryRewards=False, bArmRemoval=False):
        """
        D allows diagonal regularization.
        Warning: Sp must be set to `sqrt(lam) * S` for OFUL.
        """
        self.T = T
        self.X = X
        self.Z = Z
        self.R = R
        self.lam = lam
        self.delta = .2
# 		self.S_frobnorm = S_frobnorm
# 		self.Sp = np.sqrt(self.lam) * self.S_frobnorm
        self.Sp = Sp
        self.flags = flags
        self.multiplier = float(multiplier)
        self.binaryRewards = binaryRewards
        self.bArmRemoval = bArmRemoval

        # more instance variables
        self.s = 1
        self.t = 1
        self.N1, self.d1 = self.X.shape
        self.N2, self.d2 = self.Z.shape

        # super arms
        self.N = self.N1 * self.N2
        self.d = self.d1 * self.d2
        self.W = np.zeros( (self.N, self.d) )
        for i in range(self.W.shape[0]):
            i1, i2 = np.unravel_index(i, (self.N1, self.N2))
            self.W[i,:] = np.outer(self.X[i1,:], self.Z[i2,:]).ravel()

        #- subsampling aspect (disabled for now)
        assert subsample_func == None
        self.subsample_func = None

        self.WTy = np.zeros(self.d)

        self.D = D
        if (self.D is None):
            self.Vt = self.lam * np.eye(self.d)
            self.invVt = np.eye(self.d) / self.lam
            self.W_invVt_norm_sq = np.sum(self.W * self.W, axis=1) / self.lam
            self.logdetV = self.d*log(self.lam)
        else:
            assert self.lam is None
            self.Vt = D
            self.invVt = np.diag(1/np.diag(self.Vt))
            self.W_invVt_norm_sq = np.sum((self.W*np.diag(self.invVt)) * self.W, axis=1)
            self.logdetV = np.sum(np.log(np.diag(self.Vt)))
        self.logdetV0 = self.logdetV

        self.sqrt_beta = calc_sqrt_beta_det4(self.t,self.R,self.lam,self.delta,self.Sp,self.logdetV, self.logdetV0)
        self.theta_hat = np.zeros(self.d)

        assert bArmRemoval == False # let's implement this later on.
        self.do_not_ask = []
        self.dbg_dict = {'multiplier':float(multiplier)}
        self.cache_valid_idx = np.arange(self.N)

    #@profile
    def next_arm(self):
        if (len(self.do_not_ask) == 0):
            valid_idx = self.cache_valid_idx
        else:
            valid_idx = setdiff1d(np.arange(self.N),self.do_not_ask)
        if (self.t == 1):
            return (ra.randint(self.N1), ra.randint(self.N2)), np.nan
        radius_sq = self.multiplier * (self.sqrt_beta)**2
        if (self.subsample_func == None):
#            obj_func = np.dot(self.W, self.theta_hat) + np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
#            A = np.dot(self.W, self.theta_hat)
            A = (self.X @ self.theta_hat.reshape(self.d1,self.d2) @ self.Z.T).ravel()
            B = np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
            obj_func = A + B
            truth=True
            while truth:
                if all(B[valid_idx]<(1/np.sqrt(self.T))):
                    truth=False
                    chosen_inner = np.argmax(obj_func[valid_idx])
                    chosen=valid_idx[chosen_inner]
                elif all(B[valid_idx]<2**(-self.s)):
                    borderline=max(obj_func)-2**(1-self.s)
                    self.cache_valid_idx=np.arange(self.N)[obj_func>borderline]
                    valid_idx=self.cache_valid_idx
                    self.s=self.s+1
                    #self.Vt = self.lam * np.eye(self.d)
                    #self.invVt = np.eye(self.d) / self.lam
                    #self.W_invVt_norm_sq = np.sum(self.W * self.W, axis=1) / self.lam
                    #self.logdetV = self.d*log(self.lam)
                    #self.theta_hat = np.zeros(self.d)
                    #self.WTy = np.zeros(self.d)
                    #chosen_inner = ra.randint(len(valid_idx))
                    #chosen = valid_idx[chosen_inner]
                else:
                    truth=False
                    chosen_inner = np.argmax(B[valid_idx])
                    chosen = valid_idx[chosen_inner]
        else:
            raise NotImplementedError("use valid_idx")

        chosenPair = np.unravel_index(chosen, (self.N1,self.N2))
        return chosenPair, radius_sq

    def calc_index(self):
        """ newly written for `SpectralUCB`
        """
        radius_sq = self.multiplier * (self.sqrt_beta)**2
        obj_func = np.dot(self.W, self.theta_hat) + np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
        if (self.bArmRemoval):
            obj_func[self.do_not_ask] = -np.inf
        return obj_func

    def update(self, pulled_idx_pair, y_t):
        pulled_idx = np.ravel_multi_index(pulled_idx_pair, (self.N1,self.N2))
        wt = self.W[pulled_idx, :]

        if (self.binaryRewards):
            assert (y_t >= 0.0 and y_t <= 1.0)
            self.WTy += (2*y_t - 1) * wt
        else:
            self.WTy += y_t*wt
        self.Vt += np.outer(wt,wt)

        tempval1 = np.dot(self.invVt, wt)    # d by 1, O(d^2)
        tempval2 = np.dot(tempval1, wt)      # scalar, O(d)
        self.logdetV += log(1 + tempval2)

        if (self.t % 100 == 0):
            self.invVt = la.inv(self.Vt)
        else:
#            self.invVt -= np.outer(tempval1, tempval1) / (1 + tempval2)
            aVec = tempval1 / np.sqrt(1 + tempval2)
            self.invVt -= np.outer(aVec, aVec)

        if (self.subsample_func == None):
            # self.W_invVt_norm_sq = mahalanobis_norm_sq_batch(self.W, self.invVt)  # O(Nd^2)
#            self.W_invVt_norm_sq -= (np.dot(self.W, tempval1) ** 2) / (1 + tempval2) # efficient update, O(Nd)
            v = (np.dot(self.X, tempval1.reshape(self.d1,self.d2)) @ self.Z.T).ravel()
            self.W_invVt_norm_sq -= (v ** 2) / (1 + tempval2) # efficient update, O(Nd)
            pass

        self.theta_hat = np.dot(self.invVt, self.WTy)
        if (self.bArmRemoval):
            self.do_not_ask.append( pulled_idx_pair )

        my_t = self.t + 1
        self.sqrt_beta = calc_sqrt_beta_det4(my_t,self.R,self.lam,self.delta,self.Sp,self.logdetV,self.logdetV0)

        self.t += 1

    def getDoNotAsk(self):
        return self.do_not_ask

    def predict(self, X=None):
        raise NotImplementedError()
        if X is None:
            X = self.X
        return X.dot(self.theta_hat)

    def get_debug_dict(self):
        return self.dbg_dict
########################################
########################################
class BMOracle(Bandit):
########################################
    """ this is now heavily modified for graph bandits.. for the original, please use the one in 'expr-nips17-post'
    Sp: 'S prime', for oful, should be \sqrt(lam) * (2-norm bound on theta)
        For spectral bandit, should be a bound on ||\\theta||_{V_0}
    """
    def __init__(self, X, Z, lam, r, T, cheatU, cheatV, R, Sp, D=None, flags={}, subsample_func=None, subsample_rate=1.0, multiplier=1.0, binaryRewards=False, bArmRemoval=False):
        """
        D allows diagonal regularization.
        Warning: Sp must be set to `sqrt(lam) * S` for OFUL.
        """
        self.X = X
        self.Z = Z
        self.R = R
        self.r = r
        self.lam = lam
        self.delta = .2
# 		self.S_frobnorm = S_frobnorm
# 		self.Sp = np.sqrt(self.lam) * self.S_frobnorm
        self.Sp = Sp
        self.flags = flags
        self.multiplier = float(multiplier)
        self.binaryRewards = binaryRewards
        self.bArmRemoval = bArmRemoval

        # more instance variables
        self.t = 1
        self.N1, self.d1 = self.X.shape
        self.N2, self.d2 = self.Z.shape

        # super arms
        self.N = self.N1 * self.N2
        self.d = self.d1 * self.d2
        self.W = np.zeros( (self.N, self.d) )
        for i in range(self.W.shape[0]):
            i1, i2 = np.unravel_index(i, (self.N1, self.N2))
            self.W[i,:] = np.outer(self.X[i1,:], self.Z[i2,:]).ravel()

        #For ORACLE MODIFICATION - CHEATU, CHEATV
        self.cheatU=cheatU
        self.cheatV=cheatV
        self.myX = []
        self.myZ = []
        self.myRewards = []
        self.totalT = T
        #- subsampling aspect (disabled for now)
        assert subsample_func == None
        self.subsample_func = None

        self.WTy = np.zeros(self.d)

        self.D = D
        if (self.D is None):
            self.Vt = self.lam * np.eye(self.d)
            self.invVt = np.eye(self.d) / self.lam
            self.W_invVt_norm_sq = np.sum(self.W * self.W, axis=1) / self.lam
            self.logdetV = self.d*log(self.lam)
        else:
            assert self.lam is None
            self.Vt = D
            self.invVt = np.diag(1/np.diag(self.Vt))
            self.W_invVt_norm_sq = np.sum((self.W*np.diag(self.invVt)) * self.W, axis=1)
            self.logdetV = np.sum(np.log(np.diag(self.Vt)))
        self.logdetV0 = self.logdetV

        self.sqrt_beta = 2*self.R*np.sqrt((self.d1+self.d2)*self.r*np.log(self.totalT*self.Sp*np.sqrt(self.r)/self.delta)) + self.Sp
        self.theta_hat = np.zeros(self.d)

        assert bArmRemoval == False # let's implement this later on.
        self.do_not_ask = []
        self.dbg_dict = {'multiplier':float(multiplier)}
        self.cache_valid_idx = np.arange(self.N)

    #@profile
    def next_arm(self):
        if (len(self.do_not_ask) == 0):
            valid_idx = self.cache_valid_idx
        else:
            valid_idx = setdiff1d(np.arange(self.N),self.do_not_ask)
        if (self.t == 1):
            return (ra.randint(self.N1), ra.randint(self.N2)), np.nan
        radius_sq = self.multiplier * (self.sqrt_beta)**2
        if (self.subsample_func == None):
#            obj_func = np.dot(self.W, self.theta_hat) + np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
#            A = np.dot(self.W, self.theta_hat)
            A = (self.X @ self.theta_hat.reshape(self.d1,self.d2) @ self.Z.T).ravel()
            B = np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
            obj_func = A + B
            if (len(self.do_not_ask) == 0):
                chosen = np.argmax(obj_func)
            else:
                chosen_inner = np.argmax(obj_func[valid_idx])
                chosen = valid_idx[chosen_inner]
        else:
            raise NotImplementedError("use valid_idx")

        chosenPair = np.unravel_index(chosen, (self.N1,self.N2))
        return chosenPair, radius_sq

    def calc_index(self):
        """ newly written for `SpectralUCB`
        """
        radius_sq = self.multiplier * (self.sqrt_beta)**2
        obj_func = np.dot(self.W, self.theta_hat) + np.sqrt(radius_sq) * np.sqrt(self.W_invVt_norm_sq)
        if (self.bArmRemoval):
            obj_func[self.do_not_ask] = -np.inf
        return obj_func

    def update(self, pulled_idx_pair, y_t):
        if self.t==1:
            self.myX=np.array([self.X[pulled_idx_pair[0]]])
            print(self.myX)
            self.myZ=np.array([self.Z[pulled_idx_pair[1]]])
            print(self.myZ)
        else:
            self.myX = np.concatenate((self.myX, [self.X[pulled_idx_pair[0]]]), axis=0) #################################
            self.myZ = np.concatenate((self.myZ, [self.Z[pulled_idx_pair[1]]]), axis=0)################################
        pulled_idx = np.ravel_multi_index(pulled_idx_pair, (self.N1,self.N2))
        wt = self.W[pulled_idx, :]
        self.myRewards=np.append(self.myRewards, y_t)
        if (self.binaryRewards):
            assert (y_t >= 0.0 and y_t <= 1.0)
            self.WTy += (2*y_t - 1) * wt
        else:
            self.WTy += y_t*wt
        self.Vt += np.outer(wt,wt)

        tempval1 = np.dot(self.invVt, wt)    # d by 1, O(d^2)
        tempval2 = np.dot(tempval1, wt)      # scalar, O(d)
        self.logdetV += log(1 + tempval2)

        if (self.t % 100 == 0):
            self.invVt = la.inv(self.Vt)
        else:
#            self.invVt -= np.outer(tempval1, tempval1) / (1 + tempval2)
            aVec = tempval1 / np.sqrt(1 + tempval2)
            self.invVt -= np.outer(aVec, aVec)

        if (self.subsample_func == None):
            # self.W_invVt_norm_sq = mahalanobis_norm_sq_batch(self.W, self.invVt)  # O(Nd^2)
#            self.W_invVt_norm_sq -= (np.dot(self.W, tempval1) ** 2) / (1 + tempval2) # efficient update, O(Nd)
            v = (np.dot(self.X, tempval1.reshape(self.d1,self.d2)) @ self.Z.T).ravel()
            self.W_invVt_norm_sq -= (v ** 2) / (1 + tempval2) # efficient update, O(Nd)
            pass

        #############################self.theta_hat = np.dot(self.invVt, self.WTy)
        from matrixrecovery import rankone_modif
        if self.t<1000 or (self.t%100==0):
            U, V, out_nIter, stat = rankone_modif(self.myX, self.myZ, self.myRewards, self.r, self.cheatU, self.cheatV, self.R)
            self.theta_hat=(U@V.T).ravel()
            if (self.bArmRemoval):
                self.do_not_ask.append( pulled_idx_pair )

        my_t = self.t + 1
        self.t += 1

    def getDoNotAsk(self):
        return self.do_not_ask

    def predict(self, X=None):
        raise NotImplementedError()
        if X is None:
            X = self.X
        return X.dot(self.theta_hat)

    def get_debug_dict(self):
        return self.dbg_dict


#- some functions necessary for the next class
def averageMatrixEntries(armPairs, rewards):
    matDict = {}; cntDict = {}
    for i in range(armPairs.shape[0]):
        [r,c] = armPairs[i,:]
        matDict[(r,c)] = matDict.get((r,c), 0.0) + rewards[i]
        cntDict[(r,c)] = cntDict.get((r,c), 0) + 1
    for ((r,c),v) in matDict.items():
        matDict[(r,c)] = v / cntDict[(r,c)]
    return matDict

########################################
class BilinearTwoStage(Bandit):
########################################
    """ this is now heavily modified for graph bandits.. for the original, please use the one in 'expr-nips17-post'
    """
    def __init__(self, X, Z, lam, R, S_F, sval_max, sval_min, r, C_T1, T, flags={}, subsample_func=None, subsample_rate=1.0, multiplier=1.0, binaryRewards=False, bArmRemoval=False, SpType=None, algoMatrixCompletion='optspace'):
        """
        Two stage: internally uses BilinearOful object.
        """
        self.X = X
        self.Z = Z
        self.R = R
        self.lam = lam
        self.delta = .2
        self.S_F = S_F
        self.sval_max = sval_max
        self.sval_min = sval_min
        self.r = r
        self.C_T1 = C_T1
        self.T = T
        self.flags = flags
        self.multiplier = float(multiplier)
        self.binaryRewards = binaryRewards
        self.bArmRemoval = bArmRemoval
        self.SpType = SpType
        self.algoMatrixCompletion = algoMatrixCompletion

        #- to be set in the first stage
        self.stage1arms = None
        self.stage1rewards = []
        self.hatUFull = None; self.hatVFull = None
        self.lamp = None
        self.Sp = None
        self.oful = None
        self.subsetX = None
        self.subsetZ = None

        # more instance variables
        self.t = 1
        self.N1, self.d1 = self.X.shape
        self.N2, self.d2 = self.Z.shape
        assert (self.d1 == self.d2)
        d = self.d1     # FIXME I should change this

        #- old scheme; saved for reference..
        # myT1 = int(np.ceil(C_T1 * self.R * d**(3/2) * r**(1/2) * np.sqrt(self.T)))
        # self.T1 = np.maximum( myT1, self.r*(self.d1 + self.d2) - self.r**2 )

        #- new scheme
        minT1 = self.r*(self.d1 + self.d2) - self.r**2 
        self.T1 = int(np.ceil(C_T1 * minT1))

        self.dbg_dict = {}

    def next_arm(self):
        if (self.t == 1):
            # prepare representative arms.
            self.subsetX, self.invX_norm = calcsubset.hybrid(self.X, 20)
            self.subsetZ, self.invZ_norm = calcsubset.hybrid(self.Z, 20)
            self.subsetXInv = dict(zip(self.subsetX, range(len(self.subsetX))))
            self.subsetZInv = dict(zip(self.subsetZ, range(len(self.subsetZ))))

            mat = dstack_product(self.subsetX, self.subsetZ)   # num of super arms (d^2) by 2
            idxAry = ra.permutation(mat.shape[0])
            nRepeat = int((self.T1 - 1) // len(idxAry) + 1)
            idxAry = np.squeeze(np.tile(idxAry, (1,nRepeat)))
            self.stage1arms = mat[idxAry[:self.T1],:]
            self.stage1rewards = nans(self.T1)

            #- if there is an empty row / column, then ensure that there is no empty row/column.
            sa = self.stage1arms
            if len(np.unique(sa[:,0])) != self.d1 or len(np.unique(sa[:,1])) != self.d2:
                idxDiagonals = np.arange(0,len(mat),self.d2+1)
                idxRemainders = np.setdiff1d(range(len(mat)), idxDiagonals)
                idxRemainders = ra.permutation(idxRemainders)
                oneTile = np.concatenate( (idxDiagonals,idxRemainders) )

                nRepeat = int((self.T1 - 1) // len(idxAry) + 1)
                idxAry = np.squeeze(np.tile(oneTile, (1,nRepeat)))
                self.stage1arms = mat[idxAry[:self.T1],:]
            
            #- save necessary stats
            self.dbg_dict['T1'] = self.T1
            printExpr("self.T1")
            pass

        if (self.t <= self.T1):
            armPairToPull = tuple(self.stage1arms[self.t-1,:])
            radius_sq = np.nan
        else:
            # at the beginning of the second stage
            if (self.t == self.T1+1):
                #----- invoke matrix completion
                    #- average out entries observed more than once.; stage1arms: list of (lArmIdx,rArmIdx).
                matDict = averageMatrixEntries(self.stage1arms, self.stage1rewards)
                    #- translate index
                smat = [(self.subsetXInv[k1],self.subsetZInv[k2],v) for ((k1,k2),v) in matDict.items()]
                    #- run optspace and but catch the stdout
                if self.algoMatrixCompletion == 'optspace':
                    import optspace
                    [U,S,V,out_niter] = optspace.optspace(smat, rank_n=self.r, 
                                    num_iter=1000, 
                                    tol=1e-4, 
                                    verbosity=0, 
                                    outfile="")
                    printExpr('out_niter')
                    hatK = (U @ S @ V.T)
                    self.dbg_dict['out_niter'] = out_niter
                    assert np.all(np.logical_and(~np.isnan(hatK),~np.isinf(hatK)))
                elif self.algoMatrixCompletion == 'bm':
                    myX = []; myZ = []; myRewards = []
                    for ((k1,k2),v) in matDict.items():
                        myX.append( indicator(self.subsetXInv[k1],self.d1) )
                        myZ.append( indicator(self.subsetZInv[k2],self.d2) )
                        myRewards.append( v )
                    myX = np.array(myX) 
                    myZ = np.array(myZ)
                    myRewards = np.array(myRewards)

                    from matrixrecovery import rankone
                    U,V,out_nIter,stat = rankone(myX,myZ,myRewards,self.r,self.R)
                    printExpr('out_nIter')
                    hatK = U@V.T
                    self.dbg_dict['out_nIter'] = out_nIter
                    assert np.all(np.logical_and(~np.isnan(hatK),~np.isinf(hatK)))
                else:
                    raise ValueError()

                #- Instead of the following, we do a robust version of the same operation
                #- hatTh = la.inv(self.X[self.subsetX,:]) @ hatK @ la.inv(self.Z[self.subsetZ,:].T) 
                #- note lstsq is like solve(), but solves approximately when ill-conditioned
# 				tmp = la.solve(self.X[self.subsetX,:], hatK)
# 				self.hatThStage1 = la.solve(self.Z[self.subsetZ,:], tmp.T).T
                tmp, _,_,_ = la.lstsq(self.X[self.subsetX,:], hatK, rcond=None)
                tmp2, _,_,__ = la.lstsq(self.Z[self.subsetZ,:], tmp.T, rcond=None)
                self.hatThStage1 = tmp2.T

                #- get the subspaces
                [self.hatUFull, self.hatSFull, VT] = la.svd(self.hatThStage1)
                self.hatVFull = VT.T

                #- rotate the arms
                self.newX = self.X @ self.hatUFull
                self.newZ = self.Z @ self.hatVFull

                #- prepare oful
                d = self.d1 # FIXME just an impromptu
                T2 = self.T - self.T1
                self.lamp = T2/d/self.r/np.log(1+T2/self.lam) # FIXME I think I should use T rather than T2...
                term1 = np.sqrt(self.lam) * self.S_F #2 * np.sqrt(d*self.r)

                kappa = self.sval_max / self.sval_min
                Cp_Cpp = 1
                term2 = np.sqrt(self.lamp)  \
                      * Cp_Cpp**2 * kappa**4 * self.R**2 * d**3 * self.r / self.sval_min**2 / self.T1 \
                      * self.invX_norm**2 * self.invZ_norm**2

                if   self.SpType == None:
                    self.Sp = term1 + self.sval_max * term2
                elif self.SpType == 'simple':
                    term2p = np.sqrt(self.lamp)  \
                      * self.R**2 * d**3 * self.r / self.T1 \
                      * self.invX_norm**2 * self.invZ_norm**2 
                    self.Sp = term1 + self.sval_max * term2p
                elif self.SpType == 'simple2':
                    term2pp = np.sqrt(self.lamp)  \
                      * self.R**2 * d**3 * self.r / self.T1
                    self.Sp = term1 + self.sval_max * term2pp
                elif self.SpType == 'simple3':
                    self.Sp = term1 
                else:
                    raise ValueError()

                k = self.r*(self.d1 + self.d2) - self.r**2
                p = self.d1*self.d2
                diagvec = [self.lam]*(self.r * self.d2)
                row = [self.lam]*(self.r) + [self.lamp]*(self.d2 - self.r)
                diagvec += row*(self.d1 - self.r)
                self.D = np.diag(diagvec)                
#                self.D = np.diag([self.lam]*k + [self.lamp]*(p-k))

                #- initialize oful
                self.oful = BilinearOful(X=self.newX, Z=self.newZ, 
                                         lam=None, R=self.R, Sp=self.Sp, D=self.D,
                                         flags={}, multiplier=self.multiplier)

                #- pseudo play oful, so it is up to date!
                for myt in range(self.T1):
                    self.oful.update( tuple(self.stage1arms[myt,:]), self.stage1rewards[myt] )

            #- get the next arm from oful 
            armPairToPull, radius_sq = self.oful.next_arm()

        return armPairToPull, radius_sq

    def update(self, pulled_arm_pair, y_t):
        if (self.t <= self.T1):
            assert(pulled_arm_pair == tuple(self.stage1arms[self.t-1,:]))
            self.stage1rewards[self.t-1] = y_t
        else:
            self.oful.update(pulled_arm_pair, y_t)

        self.t += 1

    def getDoNotAsk(self):
        return self.do_not_ask

    def predict(self, X=None):
        raise NotImplementedError()
        if X is None:
            X = self.X
        return X.dot(self.theta_hat)

    def get_debug_dict(self):
        return self.dbg_dict








########################################
class LowPopArt_rankone(Bandit):
########################################
    """ this is rank one version.
    """
    def __init__(self, X, Z, lam, R, S_F, sval_max, sval_min, r, C_T1, T, flags={}, subsample_func=None, subsample_rate=1.0, multiplier=1.0, binaryRewards=False, bArmRemoval=False, SpType=None, algoMatrixCompletion='optspace'):
        """
        Two stage: internally uses BilinearOful object.
        """
        self.X = X
        self.Z = Z
        self.R = R
        self.lam = lam
        self.delta = .2
        self.S_F = S_F
        self.sval_max = sval_max
        self.sval_min = sval_min
        self.r = r
        self.C_T1 = C_T1
        self.T = T
        self.flags = flags
        self.multiplier = float(multiplier)
        self.binaryRewards = binaryRewards
        self.bArmRemoval = bArmRemoval
        self.SpType = SpType

        #- to be set in the first stage
        self.stage1arms = None
        self.stage1rewards = []
        self.hatUFull = None; self.hatVFull = None
        self.lamp = None
        self.Sp = None
        self.oful = None
        self.subsetX = None
        self.subsetZ = None

        # more instance variables
        self.t = 1
        self.N1, self.d1 = self.X.shape
        self.N2, self.d2 = self.Z.shape
        assert (self.d1 == self.d2)
        d = self.d1     # FIXME I should change this

        #- old scheme; saved for reference..
        # myT1 = int(np.ceil(C_T1 * self.R * d**(3/2) * r**(1/2) * np.sqrt(self.T)))
        # self.T1 = np.maximum( myT1, self.r*(self.d1 + self.d2) - self.r**2 )

        #- new scheme
        minT1 = self.r*(self.d1 + self.d2) - self.r**2 
        self.T1 = int(np.ceil(C_T1 * minT1))

        self.dbg_dict = {}

    def next_arm(self):
        if (self.t == 1):
            # prepare representative arms.
            self.subsetX, self.invX_norm = calcsubset.hybrid(self.X, 20)
            self.subsetZ, self.invZ_norm = calcsubset.hybrid(self.Z, 20)
            self.subsetXInv = dict(zip(self.subsetX, range(len(self.subsetX))))
            self.subsetZInv = dict(zip(self.subsetZ, range(len(self.subsetZ))))

            mat = dstack_product(self.subsetX, self.subsetZ)   # num of super arms (d^2) by 2
            idxAry = ra.permutation(mat.shape[0])
            nRepeat = int((self.T1 - 1) // len(idxAry) + 1)
            idxAry = np.squeeze(np.tile(idxAry, (1,nRepeat)))
            self.stage1arms = mat[idxAry[:self.T1],:]
            self.stage1rewards = nans(self.T1)

            #- if there is an empty row / column, then ensure that there is no empty row/column.
            sa = self.stage1arms
            if len(np.unique(sa[:,0])) != self.d1 or len(np.unique(sa[:,1])) != self.d2:
                idxDiagonals = np.arange(0,len(mat),self.d2+1)
                idxRemainders = np.setdiff1d(range(len(mat)), idxDiagonals)
                idxRemainders = ra.permutation(idxRemainders)
                oneTile = np.concatenate( (idxDiagonals,idxRemainders) )

                nRepeat = int((self.T1 - 1) // len(idxAry) + 1)
                idxAry = np.squeeze(np.tile(oneTile, (1,nRepeat)))
                self.stage1arms = mat[idxAry[:self.T1],:]
            
            #- save necessary stats
            self.dbg_dict['T1'] = self.T1
            printExpr("self.T1")
            pass

        if (self.t <= self.T1):
            armPairToPull = tuple(self.stage1arms[self.t-1,:])
            radius_sq = np.nan
        else:
            # at the beginning of the second stage
            if (self.t == self.T1+1):
                #----- invoke matrix completion
                    #- average out entries observed more than once.; stage1arms: list of (lArmIdx,rArmIdx).
                matDict = averageMatrixEntries(self.stage1arms, self.stage1rewards)
                    #- translate index
                smat = [(self.subsetXInv[k1],self.subsetZInv[k2],v) for ((k1,k2),v) in matDict.items()]
                    #- run optspace and but catch the stdout
                if self.algoMatrixCompletion == 'optspace':
                    import optspace
                    [U,S,V,out_niter] = optspace.optspace(smat, rank_n=self.r, 
                                    num_iter=1000, 
                                    tol=1e-4, 
                                    verbosity=0, 
                                    outfile="")
                    printExpr('out_niter')
                    hatK = (U @ S @ V.T)
                    self.dbg_dict['out_niter'] = out_niter
                    assert np.all(np.logical_and(~np.isnan(hatK),~np.isinf(hatK)))
                elif self.algoMatrixCompletion == 'bm':
                    myX = []; myZ = []; myRewards = []
                    for ((k1,k2),v) in matDict.items():
                        myX.append( indicator(self.subsetXInv[k1],self.d1) )
                        myZ.append( indicator(self.subsetZInv[k2],self.d2) )
                        myRewards.append( v )
                    myX = np.array(myX) 
                    myZ = np.array(myZ)
                    myRewards = np.array(myRewards)

                    from matrixrecovery import rankone
                    U,V,out_nIter,stat = rankone(myX,myZ,myRewards,self.r,self.R)
                    printExpr('out_nIter')
                    hatK = U@V.T
                    self.dbg_dict['out_nIter'] = out_nIter
                    assert np.all(np.logical_and(~np.isnan(hatK),~np.isinf(hatK)))
                else:
                    raise ValueError()

                #- Instead of the following, we do a robust version of the same operation
                #- hatTh = la.inv(self.X[self.subsetX,:]) @ hatK @ la.inv(self.Z[self.subsetZ,:].T) 
                #- note lstsq is like solve(), but solves approximately when ill-conditioned
# 				tmp = la.solve(self.X[self.subsetX,:], hatK)
# 				self.hatThStage1 = la.solve(self.Z[self.subsetZ,:], tmp.T).T
                tmp, _,_,_ = la.lstsq(self.X[self.subsetX,:], hatK, rcond=None)
                tmp2, _,_,__ = la.lstsq(self.Z[self.subsetZ,:], tmp.T, rcond=None)
                self.hatThStage1 = tmp2.T

                #- get the subspaces
                [self.hatUFull, self.hatSFull, VT] = la.svd(self.hatThStage1)
                self.hatVFull = VT.T

                #- rotate the arms
                self.newX = self.X @ self.hatUFull
                self.newZ = self.Z @ self.hatVFull

                #- prepare oful
                d = self.d1 # FIXME just an impromptu
                T2 = self.T - self.T1
                self.lamp = T2/d/self.r/np.log(1+T2/self.lam) # FIXME I think I should use T rather than T2...
                term1 = np.sqrt(self.lam) * self.S_F #2 * np.sqrt(d*self.r)

                kappa = self.sval_max / self.sval_min
                Cp_Cpp = 1
                term2 = np.sqrt(self.lamp)  \
                      * Cp_Cpp**2 * kappa**4 * self.R**2 * d**3 * self.r / self.sval_min**2 / self.T1 \
                      * self.invX_norm**2 * self.invZ_norm**2

                if   self.SpType == None:
                    self.Sp = term1 + self.sval_max * term2
                elif self.SpType == 'simple':
                    term2p = np.sqrt(self.lamp)  \
                      * self.R**2 * d**3 * self.r / self.T1 \
                      * self.invX_norm**2 * self.invZ_norm**2 
                    self.Sp = term1 + self.sval_max * term2p
                elif self.SpType == 'simple2':
                    term2pp = np.sqrt(self.lamp)  \
                      * self.R**2 * d**3 * self.r / self.T1
                    self.Sp = term1 + self.sval_max * term2pp
                elif self.SpType == 'simple3':
                    self.Sp = term1 
                else:
                    raise ValueError()

                k = self.r*(self.d1 + self.d2) - self.r**2
                p = self.d1*self.d2
                diagvec = [self.lam]*(self.r * self.d2)
                row = [self.lam]*(self.r) + [self.lamp]*(self.d2 - self.r)
                diagvec += row*(self.d1 - self.r)
                self.D = np.diag(diagvec)                
#                self.D = np.diag([self.lam]*k + [self.lamp]*(p-k))

                #- initialize oful
                self.oful = BilinearOful(X=self.newX, Z=self.newZ, 
                                         lam=None, R=self.R, Sp=self.Sp, D=self.D,
                                         flags={}, multiplier=self.multiplier)

                #- pseudo play oful, so it is up to date!
                for myt in range(self.T1):
                    self.oful.update( tuple(self.stage1arms[myt,:]), self.stage1rewards[myt] )

            #- get the next arm from oful 
            armPairToPull, radius_sq = self.oful.next_arm()

        return armPairToPull, radius_sq

    def update(self, pulled_arm_pair, y_t):
        if (self.t <= self.T1):
            assert(pulled_arm_pair == tuple(self.stage1arms[self.t-1,:]))
            self.stage1rewards[self.t-1] = y_t
        else:
            self.oful.update(pulled_arm_pair, y_t)

        self.t += 1

    def getDoNotAsk(self):
        return self.do_not_ask

    def predict(self, X=None):
        raise NotImplementedError()
        if X is None:
            X = self.X
        return X.dot(self.theta_hat)

    def get_debug_dict(self):
        return self.dbg_dict




################################################################################
# for experiments
################################################################################
class DataForBilinearBandit(object):
    def __init__(self):
        raise NotImplementedError()

    def gen_data(self):
        raise NotImplementedError()

    def get_reward(self, idx_pair):
        raise NotImplementedError()

def genRandomFeatures(A, r, d):
    """
    A: N × N matrix. the rank is r.
    extract features of rows/cols of A so that
    A = F @ Th @ G.T, where F and G are N × d, and Th is d × d (and rank r)
    """
    U,S,VH = la.svd(A)
    S = S[:r]
    r = len(S)
    U = U[:,:r] * np.sqrt(S)
    V = VH.T
    V = V[:,:r] * np.sqrt(S)

    B = ra.randn(d,r)
    F = U @ la.pinv(B)
    D = ra.randn(d,r)
    G = V @ la.pinv(D)

    Th = B@D.T

    return F, Th, G

class MovieLense(DataForBilinearBandit):
    def __init__(self, filename, R): #, d=16, r=5):
        self.R = R
        self.filename = filename
        self.rawdata = LoadPickle(self.filename)
        self.M = self.rawdata['M']
        self.N1, self.N2 = self.M.shape
    
    def gen_features(self, d=16, r=5):
        self.d = d
        self.r = r
        self.X, self.Th, self.Z = genRandomFeatures(self.M, r,d)

        self.S_F = la.norm(self.Th, 'fro')
        self._save_expected_rewards()

    def _save_expected_rewards(self):
        self.expt_reward = (self.X @ self.Th) @ self.Z.T
        self.best_arm_pair = tuple(np.unravel_index(np.argmax(self.expt_reward),
                                              self.expt_reward.shape))

    def get_reward(self, idx_pair):
        x = self.X[idx_pair[0],:]
        z = self.Z[idx_pair[1],:]
        return x @ self.Th @ z + self.R * ra.normal(0,1)

    def get_best_reward(self):
        return self.expt_reward[self.best_arm_pair]

    def get_expected_reward(self, idx_pair):
        """ can also take idx_pair as a list of index pairs (list of tuples)
        """
        return [data.expt_reward[row[0],row[1]] for row in idx_pair]

    def get_expected_regret(self, idx_pair):
        """ can also take idx_pair as a list of index pairs (list of tuples)
        """
        x = self.best_arm_pair[0]
        z = self.best_arm_pair[1]
        return self.expt_reward[x,z] - self.expt_reward[idx_pair[0], idx_pair[1]]
        if type(idx_pair) is list:
            return self.expt_reward[x,z] - self.get_expected_reward(self, idx_pair)

    def __str__(self):
        return str(self.__dict__)
    pass


class SphericalGaussian(DataForBilinearBandit):
    def __init__(self, R, r):
        self.R = R
        self.r = r

    def set_X_Z(self, X, Z):
        self.X = X
        self.Z = Z
        [self.N1, self.d1] = X.shape
        [self.N2, self.d2] = Z.shape
        self.N = N1*N2
        self.d = d1*d2


    def gen_theta_star(self, S_2norm=1.0):
        self._gen_theta_star(S_2norm)
        self._save_expected_rewards_()

    def _gen_theta_star(self, S_2norm=1.0):
        self.S_2norm = S_2norm

        #- generate Th
        v = ra.normal(0,1,self.d1*self.d2)
        Th0 = np.reshape(v, (self.d1, self.d2));
        if (self.r != np.min([self.d1, self.d2])):
            #- FIXME this part is buggy; use V there is actually V.T... 
            #-       but I will keep this for reproducibility
            U,s,V = la.svd(Th0)
            Th0 = (U[:,:self.r] * s[:self.r]) @ V[:,:self.r].T
        Th0 = Th0 / la.norm(Th0,2) # normalize by its two norm
        self.cheatU=U[:,:self.r]
        self.cheatV=V[:,:self.r]
        self.Th = Th0 * self.S_2norm
        self.S_F = la.norm(self.Th, 'fro')

    def _save_expected_rewards(self):
        self.expt_reward = (self.X @ self.Th) @ self.Z.T
        self.best_arm_pair = tuple(np.unravel_index(np.argmax(self.expt_reward),
                                              self.expt_reward.shape))

    @staticmethod
    def _genRademacher(N,d):
        return 2 * ra.randint(2,size=(N,d)) - 1

    def gen_data(self, d1, d2, N1, N2, S=1.0, armtype="gaussian"):
        """ type could be 'gaussian' or 'rademacher'
        """
        [self.d1, self.d2] = [d1, d2]
        [self.N1, self.N2] = [N1, N2]
        self.S = S

        if (armtype == "gaussian"):
            #- generate X
            X = ra.normal(0,1,(self.N1, self.d1))
            norms = la.norm(X, axis=1)
            X /= norms.reshape(-1,1)

            #- generate X
            Z = ra.normal(0,1,(self.N2, self.d2))
            norms = la.norm(Z, axis=1)
            Z /= norms.reshape(-1,1)

            #- save expected rewards
            self._gen_theta_star(self.S) 
        elif armtype == "rademacher":
            X = self.__class__._genRademacher(self.N1, self.d1)
            Z = self.__class__._genRademacher(self.N2, self.d2)
            #- save expected rewards
            self._gen_theta_star(self.S) # this is being repeated, but I keep this for replicability
        elif armtype == "rademacher2":
            #- ensure that there exists the arm with the largest reward!
            self._gen_theta_star(self.S)
            X = self.__class__._genRademacher(self.N1, self.d1)
            Z = self.__class__._genRademacher(self.N2, self.d2)
            U,S,VT = la.svd(self.Th)
            V = VT.T
            #- implant (nearly) best arm
            i1 = ra.randint(self.N1)
            X[i1,:] = np.sign(U[:,0])
            i2 = ra.randint(self.N2)
            Z[i2,:] = np.sign(V[:,0])
        else:
            raise ValueError()
        self.X = X; self.Z = Z
        self._save_expected_rewards()

    def get_reward(self, idx_pair):
        x = self.X[idx_pair[0],:]
        z = self.Z[idx_pair[1],:]
        return x @ self.Th @ z + self.R * ra.normal(0,1)

    def get_best_reward(self):
        return self.expt_reward[self.best_arm_pair]

    def get_expected_reward(self, idx_pair):
        """ can also take idx_pair as a list of index pairs (list of tuples)
        """
        return [data.expt_reward[row[0],row[1]] for row in idx_pair]

    def get_expected_regret(self, idx_pair):
        """ can also take idx_pair as a list of index pairs (list of tuples)
        """
        x = self.best_arm_pair[0]
        z = self.best_arm_pair[1]
        return self.expt_reward[x,z] - self.expt_reward[idx_pair[0], idx_pair[1]]
        if type(idx_pair) is list:
            return self.expt_reward[x,z] - self.get_expected_reward(self, idx_pair)

    def __str__(self):
        return str(self.__dict__)


#@profile
def run_bilinear_bandit(learner, data_obj, T, initIdx=-1,timeList=[]):
    reward_ary = np.zeros(T)
    arm_pair_ary = np.zeros((T,2), dtype=int16)
    inst_regret = np.zeros(T)
    cum_regret = np.zeros(T)

    #- initial point, if given
    if initIdx != -1:
        learner.update(initIdx, 1)

    my_tt = tic()
    for t in range(1,T+1):
        #- choose the next arm
        next_arm_pair, radius_sq = learner.next_arm()

        #- get reward and update the model
        reward = data_obj.get_reward(next_arm_pair)
        learner.update(next_arm_pair, reward)

        #- save stats
        reward_ary[t-1] = reward
        arm_pair_ary[t-1,:] = next_arm_pair
        inst_regret[t-1] = data_obj.get_expected_regret(next_arm_pair)
        if (t == 1):
            cum_regret[t-1] = inst_regret[t-1]
        else:
            cum_regret[t-1] = cum_regret[t-2] + inst_regret[t-1]

        # if (t % 300 == 0):
        #     print('%.4g' % toc(my_tt))
        #     print('%.4g' % learner.time_cvx)
        #     ipdb.set_trace()
        #     pass

        #- print out stats
        if (t % 500 == 0):
            timeSoFar = toc(my_tt)
            print(('t=%d, time=%.1f, radius_sq= %.4f, inst_reg=%.4f, cum_reg=%.4f' % \
                    (t, timeSoFar, radius_sq, inst_regret[t-1], cum_regret[t-1])))
            timeList.append( [t,timeSoFar] )
            sys.stdout.flush()

    return reward_ary, arm_pair_ary, learner.get_debug_dict()

def run_bilinear_bandit_time(bandit,data_obj,T,initIdx=-1):
    timeList = []
    reward_ary, arm_pair_ary, dbg_dict = run_bilinear_bandit(bandit,data_obj,T,initIdx, timeList=timeList)
    return reward_ary, arm_pair_ary, dbg_dict, timeList

